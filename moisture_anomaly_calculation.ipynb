{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import rasterio.mask\n",
    "import shapely.wkt\n",
    "import shutil\n",
    "import re\n",
    "import rasterio.mask as riomask\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "from sentinel2download.overlap import Sentinel2Overlap\n",
    "from sentinel2download.downloader import Sentinel2Downloader\n",
    "\n",
    "from code.index_research import calculate_ndmi, calculate_ndvi\n",
    "from code.utils import stitch_tiles, dump_no_data_geojson\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REQUEST_ID=os.getenv('REQUEST_ID')\n",
    "START_DATE=os.getenv('START_DATE')\n",
    "END_DATE=os.getenv('END_DATE')\n",
    "AOI=os.getenv('AOI')\n",
    "SENTINEL2_GOOGLE_API_KEY=os.getenv('SENTINEL2_GOOGLE_API_KEY')\n",
    "SATELLITE_CACHE_FOLDER=os.getenv('SENTINEL2_CACHE')\n",
    "OUTPUT_FOLDER=os.getenv('OUTPUT_FOLDER')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Transform AOI got GeoJSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi_polygon = shapely.wkt.loads(AOI)\n",
    "aoi = gpd.GeoDataFrame(geometry=[aoi_polygon], crs=\"epsg:4326\")\n",
    "\n",
    "aoi_filename = f\"{time.time()}_aoi.geojson\"\n",
    "aoi.to_file(aoi_filename, driver=\"GeoJSON\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Overlap AOI with sentinel2grid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2overlap = Sentinel2Overlap(aoi_path=aoi_filename)\n",
    "overlap_tiles = s2overlap.overlap_with_geometry()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = os.getcwd()\n",
    "NDMI_PATH = os.path.join(BASE, f'data/rasters/{REQUEST_ID}_ndmi.tif')\n",
    "NDVI_PATH = os.path.join(BASE, f'data/rasters/{REQUEST_ID}_ndvi.tif')\n",
    "BANDS = {'B04', 'B08', 'B12', 'TCI', 'CLD'}\n",
    "\n",
    "NODATA_PIXEL_PERCENTAGE = 10.0\n",
    "SEARCH_CLOUDY_PIXEL_PERCENTAGE = 80.0\n",
    "AOI_CLOUDY_PIXEL_PERCENTAGE = 15.0\n",
    "CONSTRAINTS = {'CLOUDY_PIXEL_PERCENTAGE': SEARCH_CLOUDY_PIXEL_PERCENTAGE}\n",
    "PRODUCT_TYPE = 'L2A'\n",
    "NAME = 'Moisture content'\n",
    "\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Check whether downloaded tiles match constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_nodata_percentage_crop(tile_path, \n",
    "                                 aoi, \n",
    "                                 nodata_percentage_limit, \n",
    "                                 nodata):\n",
    "    with rasterio.open(tile_path) as src:\n",
    "        polygon = aoi.to_crs(src.meta['crs']).geometry[0]\n",
    "        band, _ = rasterio.mask.mask(src, [polygon], crop=True, filled=False, indexes=1)\n",
    "        masked_band = band[~band.mask]\n",
    "        nodata_count = np.count_nonzero(masked_band == nodata)\n",
    "        nodata_percentage = round(nodata_count / masked_band.size * 100, 2)\n",
    "    if nodata_percentage>=nodata_percentage_limit:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def check_cloud_percentage_crop(tile_path, \n",
    "                                aoi, \n",
    "                                cloud_percentage_limit,\n",
    "                                cloud_probability=50):\n",
    "    with rasterio.open(tile_path) as src:\n",
    "        polygon = aoi.to_crs(src.meta['crs']).geometry[0]\n",
    "        band, _ = rasterio.mask.mask(src, [polygon], crop=True, filled=False, indexes=1)\n",
    "        masked_band = band[~band.mask]\n",
    "        cloud_count = np.count_nonzero(masked_band >= cloud_probability)\n",
    "        cloud_percentage = round(cloud_count / masked_band.size * 100, 2)\n",
    "    if cloud_percentage>=cloud_percentage_limit:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def check_tile_validity(tile_folder, aoi, cloud_percentage_limit, nodata_percentage_limit):\n",
    "    band_paths = [os.path.join(tile_folder, i) for i in os.listdir(tile_folder)]\n",
    "    skip_tile = False\n",
    "    for band_path in band_paths:\n",
    "        if  '.jp2' != Path(band_path).suffix:\n",
    "            continue\n",
    "        if \"MSK_CLDPRB_20m\" in band_path:\n",
    "            cloud_check = check_cloud_percentage_crop(band_path, aoi, cloud_percentage_limit)\n",
    "            if cloud_check:\n",
    "                skip_tile=True\n",
    "                break\n",
    "        else:\n",
    "            nodata_check = check_nodata_percentage_crop(band_path, aoi, nodata_percentage_limit, 0)\n",
    "            if nodata_check:\n",
    "                skip_tile=True\n",
    "                break\n",
    "    return skip_tile, band_paths\n",
    "\n",
    "def validate_tile_downloads(loaded, tile, loadings, aoi, cloud_percentage_limit, nodata_percentage_limit):\n",
    "    print(f\"Validating images for tile: {tile}...\")\n",
    "    if not loaded:\n",
    "        print(f\"Images for tile {tile} were not loaded!\")\n",
    "        return loadings\n",
    "    loaded_tile_folders = set([Path(i[0]).parent for i in loaded])\n",
    "    tile_bands = []\n",
    "    for loaded_tile_folder in loaded_tile_folders:\n",
    "        skip_tile, band_paths = check_tile_validity(loaded_tile_folder, aoi, cloud_percentage_limit, nodata_percentage_limit)\n",
    "        if skip_tile:\n",
    "            shutil.rmtree(loaded_tile_folder)\n",
    "        else:\n",
    "            tile_bands += band_paths\n",
    "    if tile_bands:\n",
    "        loadings[tile] = tile_bands\n",
    "    else:\n",
    "        print(f\"Tile images didn't match nodata/cloud constraints, so they were removed\") \n",
    "    print(f\"Validating images for tile {tile} finished\")  \n",
    "    return loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(tiles, start_date, end_date, aoi):\n",
    "    loader = Sentinel2Downloader(SENTINEL2_GOOGLE_API_KEY)\n",
    "    loadings = dict()\n",
    "\n",
    "    for tile in tiles:\n",
    "        print(f\"Loading images for tile: {tile}...\")\n",
    "        loaded = loader.download(PRODUCT_TYPE,\n",
    "                            [tile],\n",
    "                            start_date=start_date,\n",
    "                            end_date=end_date,\n",
    "                            output_dir=SATELLITE_CACHE_FOLDER,               \n",
    "                            bands=BANDS,\n",
    "                            constraints=CONSTRAINTS)\n",
    "        print(f\"Loading images for tile {tile} finished\")\n",
    "        loadings = validate_tile_downloads(loaded, tile, loadings, aoi, AOI_CLOUDY_PIXEL_PERCENTAGE, NODATA_PIXEL_PERCENTAGE)\n",
    "    return loadings\n",
    "\n",
    "loadings = load_images(overlap_tiles.Name.values, START_DATE, END_DATE, aoi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_date(loadings):\n",
    "    def _find_last_date(folders):        \n",
    "        dates = list()\n",
    "        for folder in folders:        \n",
    "            search = re.search(r\"_(\\d+)T\\d+_\", str(folder))\n",
    "            date = search.group(1)\n",
    "            date = datetime.strptime(date, '%Y%m%d')\n",
    "            dates.append(date)    \n",
    "        last_date = max(dates)\n",
    "        last_date = datetime.strftime(last_date, '%Y%m%d')\n",
    "        return last_date\n",
    "    \n",
    "    filtered = {\n",
    "        'BO4': [],\n",
    "        'BO8': [],\n",
    "        'B12':[],\n",
    "        'TCI': []\n",
    "    }\n",
    "    for tile, items in loadings.items():\n",
    "        try:\n",
    "            last_date = _find_last_date(items)\n",
    "            for path in items:\n",
    "                if last_date in path:\n",
    "                    if 'B04_10m.jp2' in path:\n",
    "                        filtered['BO4'] += [path]\n",
    "                    if 'B08_10m.jp2' in path:\n",
    "                        filtered['BO8'] += [path]\n",
    "                    if 'B12_20m.jp2' in path:\n",
    "                        filtered['B12'] += [path]\n",
    "                    if 'TCI_10m.jp2' in path:\n",
    "                        filtered['TCI'] += [path]\n",
    "        except Exception as ex:\n",
    "            print(f\"Error for {tile}: {str(ex)}\")\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_tiles = filter_by_date(loadings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not filtered_tiles:\n",
    "    geojson_path = os.path.join(OUTPUT_FOLDER, f\"{START_DATE}_{END_DATE}_no_data.geojson\")\n",
    "    dump_no_data_geojson(aoi.geometry[0], geojson_path)\n",
    "    raise ValueError(\"Images not loaded for given AOI. Change dates, constraints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b04_tile = stitch_tiles(filtered_tiles['BO4'], filtered_tiles['BO4'][0].replace('.jp2', '_merged.tif'))\n",
    "b08_tile = stitch_tiles(filtered_tiles['BO8'], filtered_tiles['BO8'][0].replace('.jp2', '_merged.tif'))\n",
    "b12_tile = stitch_tiles(filtered_tiles['B12'], filtered_tiles['B12'][0].replace('.jp2', '_merged.tif'))\n",
    "tci_tile = stitch_tiles(filtered_tiles['TCI'], filtered_tiles['TCI'][0].replace('.jp2', '_merged.tif'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_ndmi(b08_tile, b12_tile, out_path=NDMI_PATH, nodata=np.nan)\n",
    "calculate_ndvi(b04_tile, b08_tile, out_path=NDVI_PATH, nodata=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(tci_tile) as src:\n",
    "    tci_image, tfs = riomask.mask(\n",
    "        src, aoi.to_crs(src.crs).geometry, all_touched=False, crop=True)\n",
    "    \n",
    "with rasterio.open(NDMI_PATH) as src:\n",
    "    ndmi, tfs = riomask.mask(\n",
    "        src, aoi.to_crs(src.crs).geometry, all_touched=False, crop=True)\n",
    "    meta = src.meta\n",
    "    meta['transform'] = tfs\n",
    "    meta['width'] = ndmi.shape[-1]\n",
    "    meta['height'] = ndmi.shape[-2]\n",
    "    \n",
    "with rasterio.open(NDVI_PATH) as src:\n",
    "    ndvi, _ = riomask.mask(\n",
    "        src, aoi.to_crs(src.crs).geometry, all_touched=False, crop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_name -> [[(ndmi_range), (ndvi_range)], [(ndmi_range), (ndvi_range)], ... ]\n",
    "\n",
    "class_names = {\n",
    "    \n",
    "    \"no water stress\": [\n",
    "        [(-0.6, -0.4), (0.1, 0.2)],\n",
    "        [(-0.4, -0.2), (0.1, 0.3)],\n",
    "        [(-0.2, 0.0), (0.1, 0.3)],\n",
    "        [(0.0, 0.2), (0.1, 0.4)],\n",
    "        [(0.2, 0.4), (0.1, 0.4)],\n",
    "        [(0.4, 0.6), (0.7, 1.0)],\n",
    "        [(0.6, 0.8), (0.6, 1.0)],\n",
    "        [(0.8, 1.0), (0.5, 1.0)],\n",
    "        \n",
    "    ],\n",
    "    \n",
    "    \"low water stress\": [\n",
    "        [(-0.6, -0.4), (0.2, 0.3)],\n",
    "        [(-0.4, -0.2), (0.3, 0.4)],\n",
    "        [(-0.2, 0.0), (0.3, 0.5)],\n",
    "        [(0.0, 0.2), (0.4, 0.7)],\n",
    "        [(0.2, 0.4), (0.4, 0.5)],\n",
    "        [(0.4, 0.6), (0.4, 0.7)],\n",
    "        [(0.6, 0.8), (0.3, 0.6)],\n",
    "        [(0.8, 1.0), (0.1, 0.5)],\n",
    "    ],\n",
    "    \n",
    "    \"high water stress\" : [\n",
    "        [(-0.6, -0.4), (0.3, 0.6)],\n",
    "        [(-0.4, -0.2), (0.4, 0.6)],\n",
    "        [(-0.2, 0.0), (0.5, 0.7)],\n",
    "        [(0.0, 0.2), (0.7, 0.9)],\n",
    "        [(0.2, 0.4), (0.5, 0.9)],\n",
    "        [(0.4, 0.6), (0.1, 0.4)],\n",
    "        [(0.6, 0.8), (0.1, 0.3)],\n",
    "    ],\n",
    "    \n",
    "    \"drought\": [\n",
    "        [(-0.4, -0.2), (0.6, 1.0)],\n",
    "        [(-0.6, -0.4), (0.6, 1.0)],\n",
    "        [(-0.2, 0.0), (0.7, 1.0)],\n",
    "        [(0.0, 0.2), (0.9, 1.0)],\n",
    "        [(0.2, 0.4), (0.9, 1.0)]\n",
    "    ]\n",
    "}\n",
    "\n",
    "NUM_CLASSES = len(class_names)\n",
    "arr = np.array(range(0, NUM_CLASSES)) / NUM_CLASSES\n",
    "\n",
    "colors = [\n",
    "    (138, 206, 126),\n",
    "    (48, 145, 67),\n",
    "    (255, 218, 102),\n",
    "    (182, 10, 28),\n",
    "]\n",
    "\n",
    "labels = []\n",
    "\n",
    "mask = np.zeros((ndmi[0].shape[-2], ndmi[0].shape[-1], 3)).astype(np.uint8)\n",
    "for idx, (name, values) in enumerate(class_names.items()):\n",
    "    class_area = 0\n",
    "    for pix_vals in values:\n",
    "        \n",
    "        ndmi_pix, ndvi_pix = pix_vals\n",
    "        class_area += np.where(((ndmi[0] >= ndmi_pix[0])&(ndmi[0] <= ndmi_pix[1])) & ((ndvi[0] >= ndvi_pix[0])&(ndvi[0] <= ndvi_pix[1])), 1, 0).sum() / 10**4 \n",
    "        mask[((ndmi[0] >= ndmi_pix[0])&(ndmi[0] <= ndmi_pix[1])) & ((ndvi[0] >= ndvi_pix[0])&(ndvi[0] <= ndvi_pix[1]))] = colors[idx]\n",
    "\n",
    "    labels.append({\n",
    "        \"color\": \",\".join(list(map(lambda x: str(int(x)), colors[idx]))),\n",
    "        \"name\": name,\n",
    "        \"area\": round(class_area, 3)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = json.dumps(labels)\n",
    "mask = mask.astype(np.float32)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.update(\n",
    "    count=3,\n",
    "    nodata=0,\n",
    "    compress='lzw',\n",
    "    photometric='RGB'\n",
    ")\n",
    "\n",
    "result_name = f\"moisture_anomaly_{START_DATE}_{END_DATE}.tif\"\n",
    "colored_tif = os.path.join(OUTPUT_FOLDER, result_name)\n",
    "tci_tif = os.path.join(OUTPUT_FOLDER, f\"tci_tile_{START_DATE}_{END_DATE}.tif\")\n",
    "\n",
    "with rasterio.open(colored_tif, 'w', **meta) as dst:\n",
    "    dst.update_tags(start_date=START_DATE, \n",
    "                    end_date=END_DATE, \n",
    "                    request_id=REQUEST_ID,\n",
    "                    labels=labels,\n",
    "                    name=NAME)\n",
    "\n",
    "    for i in range(mask.shape[-1]):\n",
    "        dst.write(mask[:,:,i], indexes=i+1)\n",
    "\n",
    "with rasterio.open(tci_tif, 'w', **meta) as dst:\n",
    "    tci_image = tci_image.astype(np.float32)\n",
    "    dst.update_tags(start_date=START_DATE, \n",
    "                    end_date=END_DATE, \n",
    "                    request_id=REQUEST_ID,\n",
    "                    labels=labels,\n",
    "                    name=NAME)\n",
    "\n",
    "    for i in range(mask.shape[-1]):\n",
    "        dst.write(tci_image[i,:,:], indexes=i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "fcebc31e3fd9bc6848e9637255bf73fc863f9eb2e5911648d8da9aafb0d40317"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
